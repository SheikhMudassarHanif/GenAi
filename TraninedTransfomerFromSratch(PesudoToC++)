{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10858525,"sourceType":"datasetVersion","datasetId":6745024},{"sourceId":269943,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":231010,"modelId":252766}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport pandas as pd\nimport nltk\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\nimport math\n\nnltk.download('punkt')\n\n# Data Preparation\nclass CodeDataset(Dataset):\n    def __init__(self, df, src_vocab, tgt_vocab):\n        self.src_texts = df['text'].tolist()\n        self.tgt_texts = df['code'].tolist()\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n\n    def encode_text(self, text, vocab):\n        tokens = nltk.word_tokenize(str(text).lower())\n        token_ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n        return torch.tensor([vocab[\"<sos>\"]] + token_ids + [vocab[\"<eos>\"]], dtype=torch.long)\n\n    def __len__(self): return len(self.src_texts)\n    def __getitem__(self, idx): return self.encode_text(self.src_texts[idx], self.src_vocab), self.encode_text(self.tgt_texts[idx], self.tgt_vocab)\n\ndef build_vocab(texts, min_freq=2):\n    token_freq = Counter()\n    for text in texts:\n        tokens = nltk.word_tokenize(str(text).lower())\n        token_freq.update(tokens)\n    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n    for word, freq in token_freq.items():\n        if freq >= min_freq: vocab[word] = len(vocab)\n    return vocab\n\ndef collate_fn(batch):\n    src_batch, tgt_batch = zip(*batch)\n    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n    tgt_batch = torch.nn.utils.rnn.pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n    return src_batch, tgt_batch\n\n# Transformer Components (unchanged from previous version)\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe.unsqueeze(0))\n\n    def forward(self, x): return x + self.pe[:, :x.size(1)]\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n        self.d_k = d_model // num_heads\n        self.num_heads = num_heads\n        self.q_linear = nn.Linear(d_model, d_model)\n        self.k_linear = nn.Linear(d_model, d_model)\n        self.v_linear = nn.Linear(d_model, d_model)\n        self.out_linear = nn.Linear(d_model, d_model)\n\n    def forward(self, q, k, v, mask=None):\n        batch_size = q.size(0)\n        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)\n        attn = torch.softmax(scores, dim=-1)\n        context = torch.matmul(attn, v)\n        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n        return self.out_linear(context)\n\nclass FeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super().__init__()\n        self.linear1 = nn.Linear(d_model, d_ff)\n        self.linear2 = nn.Linear(d_ff, d_model)\n        self.relu = nn.ReLU()\n\n    def forward(self, x): return self.linear2(self.relu(self.linear1(x)))\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.ffn = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask): \n        attn_out = self.self_attn(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn_out))\n        ffn_out = self.ffn(x)\n        return self.norm2(x + self.dropout(ffn_out))\n\nclass DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n        super().__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.ffn = FeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        self_attn_out = self.self_attn(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout(self_attn_out))\n        cross_attn_out = self.cross_attn(x, enc_output, enc_output, src_mask)\n        x = self.norm2(x + self.dropout(cross_attn_out))\n        ffn_out = self.ffn(x)\n        return self.norm3(x + self.dropout(ffn_out))\n\nclass Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=256, num_heads=8, \n                 num_layers=3, d_ff=512, dropout=0.1):\n        super().__init__()\n        self.encoder_embed = nn.Embedding(src_vocab_size, d_model)\n        self.decoder_embed = nn.Embedding(tgt_vocab_size, d_model)\n        self.pos_enc = PositionalEncoding(d_model)\n        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n        self.dropout = nn.Dropout(dropout)\n        self.d_model = d_model\n\n    def generate_mask(self, src, tgt):\n        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n        seq_length = tgt.size(1)\n        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n        tgt_mask = tgt_mask & nopeak_mask.to(tgt.device)\n        return src_mask, tgt_mask\n\n    def forward(self, src, tgt):\n        src_mask, tgt_mask = self.generate_mask(src, tgt)\n        src_embedded = self.dropout(self.pos_enc(self.encoder_embed(src) * math.sqrt(self.d_model)))\n        tgt_embedded = self.dropout(self.pos_enc(self.decoder_embed(tgt) * math.sqrt(self.d_model)))\n        enc_output = src_embedded\n        for enc_layer in self.encoder_layers:\n            enc_output = enc_layer(enc_output, src_mask)\n        dec_output = tgt_embedded\n        for dec_layer in self.decoder_layers:\n            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n        return self.fc_out(dec_output)\n\n# Separated Training Functions\ndef train_epoch(model, data_loader, optimizer, criterion, device, clip=1.0):\n    model.train()\n    epoch_loss = 0\n    for src, tgt in data_loader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, tgt[:, :-1])\n        output_dim = output.shape[-1]\n        output = output.contiguous().view(-1, output_dim)\n        tgt = tgt[:, 1:].contiguous().view(-1)\n        loss = criterion(output, tgt)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)\n\ndef evaluate(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for src, tgt in data_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            output = model(src, tgt[:, :-1])\n            output = output.contiguous().view(-1, output.shape[-1])\n            tgt = tgt[:, 1:].contiguous().view(-1)\n            loss = criterion(output, tgt)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)\n\ndef generate_code(model, src_sentence, src_vocab, tgt_vocab, device, max_len=100):\n    model.eval()\n    tokens = nltk.word_tokenize(src_sentence.lower())\n    src_indices = [src_vocab.get(token, src_vocab[\"<unk>\"]) for token in tokens]\n    src_tensor = torch.tensor([src_vocab[\"<sos>\"]] + src_indices + [src_vocab[\"<eos>\"]], \n                            dtype=torch.long).unsqueeze(0).to(device)\n    tgt_tensor = torch.tensor([[tgt_vocab[\"<sos>\"]]], dtype=torch.long).to(device)\n    with torch.no_grad():\n        for _ in range(max_len):\n            output = model(src_tensor, tgt_tensor)\n            next_token = output[:, -1, :].argmax(-1).item()\n            tgt_tensor = torch.cat([tgt_tensor, torch.tensor([[next_token]], dtype=torch.long).to(device)], dim=1)\n            if next_token == tgt_vocab[\"<eos>\"]: break\n    reverse_vocab = {v: k for k, v in tgt_vocab.items()}\n    generated_tokens = [reverse_vocab.get(token_id, \"<unk>\") for token_id in tgt_tensor[0, 1:].tolist()]\n    return \" \".join([token for token in generated_tokens if token not in [\"<sos>\", \"<eos>\", \"<pad>\"]])\n\n# Training Process Manager\nclass Trainer:\n    def __init__(self, model, train_loader, val_loader, test_loader, device):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.device = device\n        self.optimizer = optim.Adam(model.parameters(), lr=0.0001)\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    def train(self, num_epochs):\n        for epoch in range(num_epochs):\n            train_loss = train_epoch(self.model, self.train_loader, \n                                   self.optimizer, self.criterion, self.device)\n            val_loss = evaluate(self.model, self.val_loader, \n                              self.criterion, self.device)\n            print(f\"Epoch {epoch+1}/{num_epochs}\")\n            print(f\"Train Loss: {train_loss:.4f}\")\n            print(f\"Validation Loss: {val_loss:.4f}\")\n            print(\"-\" * 50)\n\n    def test(self, test_df, src_vocab, tgt_vocab, num_samples=1):\n        self.model.eval()\n        for i in range(min(num_samples, len(test_df))):\n            test_sample = test_df['text'].iloc[i]\n            generated_code = generate_code(self.model, test_sample, \n                                        src_vocab, tgt_vocab, self.device)\n            print(f\"\\nSample {i+1}\")\n            print(f\"Input pseudo-code: {test_sample}\")\n            print(f\"Generated C++ code: {generated_code}\")\n\n    def save_model(self, filepath=\"/kaggle/working/workingModelGenAi.pth\"):\n        torch.save(self.model.state_dict(), filepath)\n        print(f\"Model saved to {filepath}\")\n\ndef main():\n    # Load datasets\n    # train_df = pd.read_csv(\"path/to/train.tsv\", sep='\\t')[['text', 'code']].dropna()\n    # val_df = pd.read_csv(\"path/to/val.tsv\", sep='\\t')[['text', 'code']].dropna()\n    # test_df = pd.read_csv(\"path/to/test.tsv\", sep='\\t')[['text', 'code']].dropna()\n    train_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-train.tsv\", sep='\\t')[['text', 'code']].dropna()\n    val_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-eval.tsv\", sep='\\t')[['text', 'code']].dropna()\n    test_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-test.tsv\", sep='\\t')[['text', 'code']].dropna()\n\n    # Build vocabularies\n    src_vocab = build_vocab(train_df['text'])\n    tgt_vocab = build_vocab(train_df['code'])\n\n    # Create datasets and dataloaders\n    train_dataset = CodeDataset(train_df, src_vocab, tgt_vocab)\n    val_dataset = CodeDataset(val_df, src_vocab, tgt_vocab)\n    test_dataset = CodeDataset(test_df, src_vocab, tgt_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n\n    # Initialize model\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = Transformer(\n        src_vocab_size=len(src_vocab),\n        tgt_vocab_size=len(tgt_vocab),\n        d_model=256,\n        num_heads=8,\n        num_layers=3,\n        d_ff=512,\n        dropout=0.1\n    ).to(device)\n\n\n    Initialize trainer\n    trainer = Trainer(model, train_loader, val_loader, test_loader, device)\n    \n    Train the model\n    print(\"Starting Training...\")\n    trainer.train(num_epochs=5)\n    \n    Test the model\n    print(\"\\nTesting Model...\")\n    trainer.test(test_df, src_vocab, tgt_vocab, num_samples=3)\n    trainer.save_model()\n\n\nif __name__ == \"__main__\":\n    \n    main()\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T10:04:22.923254Z","iopub.execute_input":"2025-02-27T10:04:22.923556Z","iopub.status.idle":"2025-02-27T10:04:22.960121Z","shell.execute_reply.started":"2025-02-27T10:04:22.923522Z","shell.execute_reply":"2025-02-27T10:04:22.959279Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-27T10:04:31.468305Z","iopub.execute_input":"2025-02-27T10:04:31.468628Z","iopub.status.idle":"2025-02-27T10:05:00.549883Z","shell.execute_reply.started":"2025-02-27T10:04:31.468604Z","shell.execute_reply":"2025-02-27T10:05:00.548931Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-8-d8521f5ee94e>:278: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(model_path, map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")))\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Add these functions if not already present\ndef train_epoch(model, data_loader, optimizer, criterion, device, clip=1.0):\n    model.train()\n    epoch_loss = 0\n    for src, tgt in data_loader:\n        src, tgt = src.to(device), tgt.to(device)\n        optimizer.zero_grad()\n        output = model(src, tgt[:, :-1])\n        output_dim = output.shape[-1]\n        output = output.contiguous().view(-1, output_dim)\n        tgt = tgt[:, 1:].contiguous().view(-1)\n        loss = criterion(output, tgt)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)\n\ndef evaluate(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for src, tgt in data_loader:\n            src, tgt = src.to(device), tgt.to(device)\n            output = model(src, tgt[:, :-1])\n            output = output.contiguous().view(-1, output.shape[-1])\n            tgt = tgt[:, 1:].contiguous().view(-1)\n            loss = criterion(output, tgt)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)\n\n# Update your Trainer class to handle loading\nclass Trainer:\n    def __init__(self, model, train_loader, val_loader, test_loader, device):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.test_loader = test_loader\n        self.device = device\n        self.optimizer = optim.Adam(model.parameters(), lr=0.0001)\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)\n\n    def train(self, num_epochs):\n        for epoch in range(num_epochs):\n            train_loss = train_epoch(self.model, self.train_loader, \n                                   self.optimizer, self.criterion, self.device)\n            val_loss = evaluate(self.model, self.val_loader, \n                              self.criterion, self.device)\n            print(f\"Epoch {epoch+1}/{num_epochs}\")\n            print(f\"Train Loss: {train_loss:.4f}\")\n            print(f\"Validation Loss: {val_loss:.4f}\")\n            print(\"-\" * 50)\n\n    def test(self, test_df, src_vocab, tgt_vocab, num_samples=1):\n        self.model.eval()\n        for i in range(min(num_samples, len(test_df))):\n            test_sample = test_df['text'].iloc[i]\n            generated_code = generate_code(self.model, test_sample, \n                                        src_vocab, tgt_vocab, self.device)\n            print(f\"\\nSample {i+1}\")\n            print(f\"Input pseudo-code: {test_sample}\")\n            print(f\"Generated C++ code: {generated_code}\")\n\n    def save_model(self, filepath=\"/kaggle/working/workingModelGenAi.pth\"):\n        torch.save(self.model.state_dict(), filepath)\n        print(f\"Model saved to {filepath}\")\n\n# Modified main function to load and extend training\ndef main():\n    # Load datasets\n    train_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-train.tsv\", sep='\\t')[['text', 'code']].dropna()\n    val_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-eval.tsv\", sep='\\t')[['text', 'code']].dropna()\n    test_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-test.tsv\", sep='\\t')[['text', 'code']].dropna()\n\n    # Build vocabularies\n    src_vocab = build_vocab(train_df['text'])\n    tgt_vocab = build_vocab(train_df['code'])\n\n    # Create datasets and dataloaders\n    train_dataset = CodeDataset(train_df, src_vocab, tgt_vocab)\n    val_dataset = CodeDataset(val_df, src_vocab, tgt_vocab)\n    test_dataset = CodeDataset(test_df, src_vocab, tgt_vocab)\n\n    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n    test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n\n    # Initialize model\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = Transformer(\n        src_vocab_size=len(src_vocab),\n        tgt_vocab_size=len(tgt_vocab),\n        d_model=256,\n        num_heads=8,\n        num_layers=3,\n        d_ff=512,\n        dropout=0.1\n    ).to(device)\n\n    # Load existing model\n    model_path = \"/kaggle/input/sudotoc/pytorch/default/1/workingModelGenAi.pth\"\n    try:\n        state_dict = torch.load(model_path, map_location=device)\n        model.load_state_dict(state_dict)\n        print(f\"Loaded pre-trained model from {model_path}\")\n    except Exception as e:\n        print(f\"Could not load model: {e}\")\n        print(\"Starting with fresh model\")\n\n    # Initialize trainer with loaded model\n    trainer = Trainer(model, train_loader, val_loader, test_loader, device)\n    \n    # Extend training\n    print(\"Continuing Training...\")\n    trainer.train(num_epochs=5)  # Add more epochs to extend training\n    \n    # Test the model\n    print(\"\\nTesting Model...\")\n    trainer.test(test_df, src_vocab, tgt_vocab, num_samples=3)\n    \n    # Save the extended model\n    trainer.save_model(\"/kaggle/working/extended_workingModelGenAi.pth\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}