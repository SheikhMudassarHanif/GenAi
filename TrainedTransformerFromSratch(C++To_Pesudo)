{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f4ef98a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-27T11:23:50.729267Z",
     "iopub.status.busy": "2025-02-27T11:23:50.728989Z",
     "iopub.status.idle": "2025-02-27T11:24:27.231464Z",
     "shell.execute_reply": "2025-02-27T11:24:27.230330Z"
    },
    "papermill": {
     "duration": 36.507207,
     "end_time": "2025-02-27T11:24:27.232869",
     "exception": false,
     "start_time": "2025-02-27T11:23:50.725662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-6bc303587192>:244: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from /kaggle/input/ctopseduv2/pytorch/default/1/workingModelGenAiq2_2.0.pth\n",
      "Input C++ code: int x; cin>>x;\n",
      "Generated pseudo-code: read x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "import math\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Data Preparation Functions\n",
    "def build_vocab(texts, min_freq=2):\n",
    "    token_freq = Counter()\n",
    "    for text in texts:\n",
    "        tokens = nltk.word_tokenize(str(text).lower())\n",
    "        token_freq.update(tokens)\n",
    "    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
    "    for word, freq in token_freq.items():\n",
    "        if freq >= min_freq: vocab[word] = len(vocab)\n",
    "    return vocab\n",
    "\n",
    "class CodeDataset(Dataset):\n",
    "    def __init__(self, df, src_vocab, tgt_vocab):\n",
    "        self.src_texts = df['code'].tolist()  # C++ code as source\n",
    "        self.tgt_texts = df['text'].tolist()  # Pseudo-code as target\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "\n",
    "    def encode_text(self, text, vocab):\n",
    "        tokens = nltk.word_tokenize(str(text).lower())\n",
    "        token_ids = [vocab.get(token, vocab[\"<unk>\"]) for token in tokens]\n",
    "        return torch.tensor([vocab[\"<sos>\"]] + token_ids + [vocab[\"<eos>\"]], dtype=torch.long)\n",
    "\n",
    "    def __len__(self): return len(self.src_texts)\n",
    "    def __getitem__(self, idx): return self.encode_text(self.src_texts[idx], self.src_vocab), self.encode_text(self.tgt_texts[idx], self.tgt_vocab)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = zip(*batch)\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    tgt_batch = torch.nn.utils.rnn.pad_sequence(tgt_batch, padding_value=0, batch_first=True)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "# Transformer Components\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x): return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.out_linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.q_linear(q).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        k = self.k_linear(k).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        v = self.v_linear(v).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None: scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        return self.out_linear(context)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): return self.linear2(self.relu(self.linear1(x)))\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask): \n",
    "        attn_out = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_out))\n",
    "        ffn_out = self.ffn(x)\n",
    "        return self.norm2(x + self.dropout(ffn_out))\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = FeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        self_attn_out = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(self_attn_out))\n",
    "        cross_attn_out = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_out))\n",
    "        ffn_out = self.ffn(x)\n",
    "        return self.norm3(x + self.dropout(ffn_out))\n",
    "\n",
    "def create_transformer(src_vocab_size, tgt_vocab_size, d_model=256, num_heads=8, \n",
    "                      num_layers=3, d_ff=512, dropout=0.1):\n",
    "    class Transformer(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            self.encoder_embed = nn.Embedding(src_vocab_size, d_model)\n",
    "            self.decoder_embed = nn.Embedding(tgt_vocab_size, d_model)\n",
    "            self.pos_enc = PositionalEncoding(d_model)\n",
    "            self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "            self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "            self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "            self.d_model = d_model\n",
    "\n",
    "        def generate_mask(self, src, tgt):\n",
    "            src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "            tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)\n",
    "            seq_length = tgt.size(1)\n",
    "            nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "            tgt_mask = tgt_mask & nopeak_mask.to(tgt.device)\n",
    "            return src_mask, tgt_mask\n",
    "\n",
    "        def forward(self, src, tgt):\n",
    "            src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "            src_embedded = self.dropout(self.pos_enc(self.encoder_embed(src) * math.sqrt(self.d_model)))\n",
    "            tgt_embedded = self.dropout(self.pos_enc(self.decoder_embed(tgt) * math.sqrt(self.d_model)))\n",
    "            enc_output = src_embedded\n",
    "            for enc_layer in self.encoder_layers:\n",
    "                enc_output = enc_layer(enc_output, src_mask)\n",
    "            dec_output = tgt_embedded\n",
    "            for dec_layer in self.decoder_layers:\n",
    "                dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "            return self.fc_out(dec_output)\n",
    "    \n",
    "    return Transformer()\n",
    "\n",
    "# Training and Testing Functions\n",
    "def train_epoch(model, data_loader, optimizer, criterion, device, clip=1.0):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, tgt in data_loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in data_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            output = model(src, tgt[:, :-1])\n",
    "            output = output.contiguous().view(-1, output.shape[-1])\n",
    "            tgt = tgt[:, 1:].contiguous().view(-1)\n",
    "            loss = criterion(output, tgt)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(data_loader)\n",
    "\n",
    "def generate_code(model, src_sentence, src_vocab, tgt_vocab, device, max_len=100):\n",
    "    model.eval()\n",
    "    tokens = nltk.word_tokenize(src_sentence.lower())\n",
    "    src_indices = [src_vocab.get(token, src_vocab[\"<unk>\"]) for token in tokens]\n",
    "    src_tensor = torch.tensor([src_vocab[\"<sos>\"]] + src_indices + [src_vocab[\"<eos>\"]], \n",
    "                            dtype=torch.long).unsqueeze(0).to(device)\n",
    "    tgt_tensor = torch.tensor([[tgt_vocab[\"<sos>\"]]], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(src_tensor, tgt_tensor)\n",
    "            next_token = output[:, -1, :].argmax(-1).item()\n",
    "            tgt_tensor = torch.cat([tgt_tensor, torch.tensor([[next_token]], dtype=torch.long).to(device)], dim=1)\n",
    "            if next_token == tgt_vocab[\"<eos>\"]: break\n",
    "    reverse_vocab = {v: k for k, v in tgt_vocab.items()}\n",
    "    generated_tokens = [reverse_vocab.get(token_id, \"<unk>\") for token_id in tgt_tensor[0, 1:].tolist()]\n",
    "    return \" \".join([token for token in generated_tokens if token not in [\"<sos>\", \"<eos>\", \"<pad>\"]])\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device, model_path=None):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    \n",
    "    # Load pre-trained model if provided\n",
    "    if model_path and os.path.exists(model_path):\n",
    "        try:\n",
    "            state_dict = torch.load(model_path, map_location=device)\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"Loaded pre-trained model from {model_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load model: {e}\")\n",
    "            print(\"Continuing with fresh model\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "    return model\n",
    "\n",
    "def test_model(model, test_df, src_vocab, tgt_vocab, device, num_samples=1):\n",
    "    model.eval()\n",
    "    for i in range(min(num_samples, len(test_df))):\n",
    "        test_sample = test_df['code'].iloc[i]  # C++ code as input\n",
    "        generated_code = generate_code(model, test_sample, src_vocab, tgt_vocab, device)\n",
    "        print(f\"\\nSample {i+1}\")\n",
    "        print(f\"Input C++ code: {test_sample}\")\n",
    "        print(f\"Generated pseudo-code: {generated_code}\")\n",
    "\n",
    "def load_model(model_path, src_vocab_size, tgt_vocab_size, device):\n",
    "    model = create_transformer(src_vocab_size, tgt_vocab_size).to(device)\n",
    "    try:\n",
    "        state_dict = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(state_dict)\n",
    "        print(f\"Loaded model from {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load model: {e}\")\n",
    "        raise\n",
    "    return model\n",
    "\n",
    "def save_model(model, filepath=\"/kaggle/working/workingModelGenAi.pth\"):\n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    print(f\"Model saved to {filepath}\")\n",
    "\n",
    "# Main Function with Mode Selection\n",
    "def main(mode=\"train\", model_path=None, test_input=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if mode == \"train\":\n",
    "        # Load datasets\n",
    "        train_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-train.tsv\", sep='\\t')[['text', 'code']].dropna()\n",
    "        val_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-eval.tsv\", sep='\\t')[['text', 'code']].dropna()\n",
    "        test_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-test.tsv\", sep='\\t')[['text', 'code']].dropna()\n",
    "\n",
    "        # Build vocabularies\n",
    "        src_vocab = build_vocab(train_df['code'])\n",
    "        tgt_vocab = build_vocab(train_df['text'])\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = CodeDataset(train_df, src_vocab, tgt_vocab)\n",
    "        val_dataset = CodeDataset(val_df, src_vocab, tgt_vocab)\n",
    "        test_dataset = CodeDataset(test_df, src_vocab, tgt_vocab)\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "        # Initialize or load model\n",
    "        model = create_transformer(len(src_vocab), len(tgt_vocab)).to(device)\n",
    "\n",
    "        # Train\n",
    "        print(\"Starting Training...\")\n",
    "        trained_model = train_model(model, train_loader, val_loader, num_epochs=5, device=device, model_path=model_path)\n",
    "\n",
    "        # Test\n",
    "        print(\"\\nTesting Model...\")\n",
    "        test_model(trained_model, test_df, src_vocab, tgt_vocab, device, num_samples=3)\n",
    "\n",
    "        # Save\n",
    "        save_model(trained_model)\n",
    "\n",
    "    elif mode == \"test\" and model_path and test_input:\n",
    "        # Load vocabularies from training data (needed for generation)\n",
    "        train_df = pd.read_csv(\"/kaggle/input/traindataset/train/split/spoc-train-train.tsv\", sep='\\t')[['text', 'code']].dropna()\n",
    "        src_vocab = build_vocab(train_df['code'])\n",
    "        tgt_vocab = build_vocab(train_df['text'])\n",
    "\n",
    "        # Load model\n",
    "        model = load_model(model_path, len(src_vocab), len(tgt_vocab), device)\n",
    "\n",
    "        # Generate output for test input\n",
    "        generated_code = generate_code(model, test_input, src_vocab, tgt_vocab, device)\n",
    "        print(f\"Input C++ code: {test_input}\")\n",
    "        print(f\"Generated pseudo-code: {generated_code}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For fresh training\n",
    "    # main(mode=\"train\")\n",
    "    \n",
    "    # For extending training with pre-trained model\n",
    "    # main(mode=\"train\", model_path=\"/kaggle/input/ctopseduv2/pytorch/default/1/workingModelGenAiq2_2.0.pth\")\n",
    "    \n",
    "    # For testing with a single input using pre-loaded model\n",
    "    main(mode=\"test\", \n",
    "         model_path=\"/kaggle/input/ctopseduv2/pytorch/default/1/workingModelGenAiq2_2.0.pth\", \n",
    "         test_input=\"int x; cin>>x;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57603a48",
   "metadata": {
    "papermill": {
     "duration": 0.001976,
     "end_time": "2025-02-27T11:24:27.237017",
     "exception": false,
     "start_time": "2025-02-27T11:24:27.235041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6745024,
     "sourceId": 10858525,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 252807,
     "modelInstanceId": 231049,
     "sourceId": 269984,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 252834,
     "modelInstanceId": 231076,
     "sourceId": 270011,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40.447688,
   "end_time": "2025-02-27T11:24:28.559531",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-27T11:23:48.111843",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
